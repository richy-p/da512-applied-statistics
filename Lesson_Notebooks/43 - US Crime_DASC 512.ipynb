{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8105b362",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.stats as stats\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.stats.api as sms\n",
    "import statsmodels.graphics.api as smg\n",
    "import statsmodels.formula.api as smf\n",
    "\n",
    "sns.set_style('darkgrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8b7adbcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def linearity_test(model, y):\n",
    "    '''\n",
    "    Function for visually inspecting the assumption of linearity in a linear regression model.\n",
    "    It plots observed vs. predicted values and residuals vs. predicted values.\n",
    "    It uses Locally Weighted Scatterplot Smoothing (LOWESS) to fit a model. \n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    * y - observed values\n",
    "    '''\n",
    "    pred = model.fittedvalues\n",
    "    influence = model.get_influence()\n",
    "    resid_std = influence.resid_studentized_internal\n",
    "    \n",
    "    fig, ax = plt.subplots(1,2, figsize=(7.5,3.5))\n",
    "    \n",
    "    sns.regplot(x=pred, y=y, lowess=True, ax=ax[0], line_kws={'color':'darkorchid'})\n",
    "    # I've added the ideal line (y=yhat) for comparison\n",
    "    sns.lineplot(x=[min(pred), max(pred)], y=[min(pred), max(pred)], \n",
    "                 ax=ax[0], color='red', ls=':')\n",
    "    ax[0].set_title('Observed vs. Fitted Values')\n",
    "    ax[0].set_xlabel('Fitted')\n",
    "    ax[0].set_ylabel('Observed')\n",
    "    \n",
    "    sns.regplot(x=pred, y=resid_std, lowess=True, ax=ax[1], line_kws={'color':'darkorchid'})\n",
    "    # I've added the ideal line (y=0) for comparison\n",
    "    sns.lineplot(x=[min(pred), max(pred)], y=[0,0], ax=ax[1], color='red', ls=':')\n",
    "    ax[1].set_title('Residuals vs. Fitted Values')\n",
    "    ax[1].set_xlabel('Fitted')\n",
    "    ax[1].set_ylabel('Standardized Residual')\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52dda267",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def homoscedasticity_test(model):\n",
    "    '''\n",
    "    Function for testing the homoscedasticity of residuals in a linear regression model.\n",
    "    It plots residuals and standardized residuals vs. fitted values and runs Breusch-Pagan \n",
    "    and Goldfeld-Quandt tests.\n",
    "    \n",
    "    Args:\n",
    "    * model - fitted OLS model from statsmodels\n",
    "    '''\n",
    "    import statsmodels.stats.api as sms\n",
    "    import seaborn as sns\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    pred = model.fittedvalues\n",
    "    resid = model.resid\n",
    "    resid_z = model.get_influence().resid_studentized_internal\n",
    "\n",
    "    fig, ax = plt.subplots(1,2, figsize=(12,5.5))\n",
    "\n",
    "    sns.regplot(x=pred, y=resid, lowess=True, ax=ax[0], line_kws={'color': 'darkorchid'})\n",
    "    # I've added the ideal line (y=0) for comparison\n",
    "    sns.lineplot(x=[min(pred), max(pred)], y=[0,0], ax=ax[0], color='red', ls=':')\n",
    "    ax[0].set_title('Residuals vs. Fitted Values')\n",
    "    ax[0].set(xlabel='Fitted', ylabel='Residual')\n",
    "\n",
    "    sns.regplot(x=pred, y=np.sqrt(np.abs(resid_z)), lowess=True, ax=ax[1], line_kws={'color': 'darkorchid'})\n",
    "    # I've added the ideal line for comparison\n",
    "    sns.lineplot(x=[min(pred), max(pred)], y=[0.822,0.822], ax=ax[1], color='red', ls=':')\n",
    "    ax[1].set_title('Scale-Location')\n",
    "    ax[1].set(xlabel='Fitted', ylabel=r'$\\sqrt{|{\\mathrm{Standardized~Residual}}|}$')\n",
    "\n",
    "    # Breusch-Pagan tests if regression on 'Residuals ~ Fitted Values' has non-zero slope\n",
    "    # Good for picking up trends of strictly increasing or decreasing variance\n",
    "    bp_test = pd.DataFrame(sms.het_breuschpagan(resid, model.model.exog), \n",
    "                           columns=['value'],\n",
    "                           index=['Lagrange multiplier statistic', 'p-value', 'f-value', 'f p-value'])\n",
    "\n",
    "    # Goldfeld-Quandt tests if variance on left half of residual plot is equal to variance on right half\n",
    "    gq_test = pd.DataFrame(sms.het_goldfeldquandt(resid, model.model.exog)[:-1],\n",
    "                           columns=['value'],\n",
    "                           index=['F statistic', 'p-value'])\n",
    "\n",
    "    print('\\n Breusch-Pagan test ----')\n",
    "    print(bp_test)\n",
    "    print('\\n Goldfeld-Quandt test ----')\n",
    "    print(gq_test)\n",
    "    print('\\n Residuals plots ----')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02384697",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def normality_of_residuals_test(model):\n",
    "    '''\n",
    "    Function for drawing the normal QQ-plot of the residuals and running 5 statistical tests to \n",
    "    investigate the normality of residuals.\n",
    "    \n",
    "    Arg:\n",
    "    * model - fitted OLS models from statsmodels\n",
    "    '''\n",
    "    import scipy.stats as stats\n",
    "    import statsmodels.graphics.api as smg\n",
    "    import statsmodels.stats.api as sms\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(4.5,4))\n",
    "    smg.qqplot(data=model.resid, line='45', fit=True, ax=ax);\n",
    "    ax.set_title('Q-Q plot');\n",
    "    resid_z = model.get_influence().resid_studentized_internal\n",
    "\n",
    "    sw = stats.shapiro(model.resid)\n",
    "    dp = stats.normaltest(model.resid)\n",
    "    jb = stats.jarque_bera(model.resid)\n",
    "    ad = stats.anderson(model.resid, dist='norm')\n",
    "    lf = sms.lilliefors(model.resid)\n",
    "    ks = stats.kstest(resid_z, 'norm')\n",
    "    \n",
    "    print(f'Shapiro-Wilk test ---- statistic: {sw[0]:.4f}, p-value: {sw[1]:.4f}')\n",
    "    print(f\"D'Agostino-Pearson Omnibus test ---- statistic: {dp[0]:.4f}, p-value: {dp[1]:.4f}\")\n",
    "    print(f'Lilliefors test ---- statistic: {lf[0]:.4f}, p-value: {lf[1]:.4f}')\n",
    "    print(f'Jarque-Bera test ---- statistic: {jb[0]:.4f}, p-value: {jb[1]}')\n",
    "    print(f'Kolmogorov-Smirnov test ---- statistic: {ks.statistic:.4f}, p-value: {ks.pvalue:.4f}')\n",
    "    print(f'Anderson-Darling test ---- statistic: {ad.statistic:.4f}, 5% critical value: {ad.critical_values[2]:.4f}')\n",
    "    print('If the returned AD statistic is larger than the critical value, then for the 5% significance level, '\\\n",
    "          'the null hypothesis that the data come from the Normal distribution should be rejected. ')\n",
    "    \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7d540452",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def autocorrelation_plot(model):\n",
    "    import statsmodels.tsa.api as smt\n",
    "    fig, ax = plt.subplots(figsize=(12,6))\n",
    "    acf = smt.graphics.plot_acf(model.resid, lags=40, alpha=0.05, ax=ax)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55d59e22",
   "metadata": {},
   "source": [
    "# US Crime Data (Feature Selection Gone Mad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cde371c0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crime = pd.read_csv('UScrime.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "506435e2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['M', 'So', 'Ed', 'Po1', 'Po2', 'LF', 'M.F', 'Pop', 'NW', 'U1', 'U2',\n",
       "       'Wealth', 'Ineq', 'Prob', 'Time', 'Crime'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "crime.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecb27dd7",
   "metadata": {},
   "source": [
    "Note: I renamed the M.F column in the csv, so you won't need to rename it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9f9aeb1e-9da8-41a9-b2af-e3f2c7e34944",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "crime.rename(columns={'M.F':'MF'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e07fb418",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# crime.drop('Unnamed: 0',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "87fe8e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "X = crime.drop('Crime',axis=1)\n",
    "y = crime['Crime']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb895846",
   "metadata": {},
   "source": [
    "## Brute Force Method\n",
    "This is only feasible for smaller datasets, especially with few or no interactions under consideration.\n",
    "However, it is possible if you have enough data for a full model (must have at least k+2 data points)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "dba7b9cc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def columns_to_formulas(X, y, max_terms=None):\n",
    "    '''\n",
    "    Function for creating all possible formulas from the columns up to \n",
    "    the given degree (adding no interactions or higher order terms)\n",
    "    \n",
    "    Args:\n",
    "    * X - the design matrix (DataFrame)\n",
    "    * y - the response data (Series)\n",
    "    * deg - the maximum degree. If deg=None, will calculate all possible interactions. By default, deg=None.\n",
    "    \n",
    "    Returns:\n",
    "    * List of Patsy formulas covering those terms\n",
    "    '''\n",
    "    from itertools import chain, combinations\n",
    "    if max_terms==None:\n",
    "        max_terms = len(X.columns)\n",
    "    formulas = []\n",
    "    models = list(\n",
    "        chain.from_iterable(\n",
    "            combinations(X.columns,terms) for terms in range(1, max_terms+1)\n",
    "        )\n",
    "    )\n",
    "    for model in models:\n",
    "        formula = y.name + ' ~ '\n",
    "        for term in model:\n",
    "            formula += term + ' + '\n",
    "        formulas.append(formula[:-3])\n",
    "    return formulas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "444ca949",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "32767"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "formulas = columns_to_formulas(X,y,max_terms=None)\n",
    "len(formulas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2d582fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "accde0a2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took a decent laptop 464.6875 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "tic = time.process_time()\n",
    "\n",
    "formulas = columns_to_formulas(X,y,max_terms=None)\n",
    "r2 = []\n",
    "r2a = []\n",
    "aic = []\n",
    "bic = []\n",
    "\n",
    "for formula in formulas:\n",
    "    model = smf.ols(formula,crime).fit()\n",
    "    r2.append(model.rsquared)\n",
    "    r2a.append(model.rsquared_adj)\n",
    "    aic.append(model.aic)\n",
    "    bic.append(model.bic)\n",
    "results = pd.DataFrame({'Formula':formulas,'R2':r2,'R2a':r2a,'AIC':aic,'BIC':bic})\n",
    "\n",
    "toc = time.process_time()\n",
    "print(f'This took a decent laptop {toc-tic:.4f} seconds to run.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bd569152",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Formula    Crime ~ M + Ed + Po1 + MF + U1 + U2 + Ineq + Prob\n",
       "R2                                                  0.788827\n",
       "R2a                                                 0.744369\n",
       "AIC                                               637.315101\n",
       "BIC                                                653.96643\n",
       "Name: 18493, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[results['R2a'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4e181fc9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Formula    Crime ~ M + Ed + Po1 + MF + U1 + U2 + Ineq + Prob\n",
       "R2                                                  0.788827\n",
       "R2a                                                 0.744369\n",
       "AIC                                               637.315101\n",
       "BIC                                                653.96643\n",
       "Name: 18493, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[results['AIC'].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57dcc6f1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Formula    Crime ~ M + Ed + Po1 + U2 + Ineq + Prob\n",
       "R2                                        0.765866\n",
       "R2a                                       0.730746\n",
       "AIC                                      638.16613\n",
       "BIC                                     651.117163\n",
       "Name: 5816, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results.iloc[results['BIC'].argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d79dd452",
   "metadata": {},
   "source": [
    "## Select K Best\n",
    "Quick but not altogether effective method for regression. Runs a regression model with all terms and takes the $k$ factors with the lowest p-values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9e894ee7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "2b710b65",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = SelectKBest(score_func=f_regression, k=5)\n",
    "fit = test.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4435b295",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Po1', 'Po2', 'Pop', 'Wealth', 'Prob'], dtype='object')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[fit.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "fc12e25c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def form(cols, y):\n",
    "    '''\n",
    "    Useful only here. Builds a Patsy formula from the outcome of K best.\n",
    "    '''\n",
    "    formula = y.name + ' ~ '\n",
    "    for term in cols:\n",
    "        formula += term + ' + '\n",
    "    return formula[:-3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe7d10eb",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "M     : 0.5498\n",
      "So    : 0.5446\n",
      "Ed    : 0.0269\n",
      "Po1   : 0.0000\n",
      "Po2   : 0.0000\n",
      "LF    : 0.2036\n",
      "MF    : 0.1488\n",
      "Pop   : 0.0204\n",
      "NW    : 0.8278\n",
      "U1    : 0.7362\n",
      "U2    : 0.2331\n",
      "Wealth: 0.0019\n",
      "Ineq  : 0.2286\n",
      "Prob  : 0.0027\n",
      "Time  : 0.3147\n"
     ]
    }
   ],
   "source": [
    "for col in X.columns:\n",
    "    model = smf.ols(f'Crime ~ {col}',crime).fit()\n",
    "    p = model.f_pvalue\n",
    "    print(f'{col:6}: {p:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70317930",
   "metadata": {},
   "source": [
    "That's really all this is doing - picking the k best from that list. Note that the next one that would be added is Ed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "180853b3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Ed', 'Po1', 'Po2', 'Pop', 'Wealth', 'Prob'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = SelectKBest(score_func=f_regression, k=6)\n",
    "fit = test.fit(X,y)\n",
    "X.columns[fit.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ee8e840b",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This took a decent laptop 0.2656 seconds to run.\n"
     ]
    }
   ],
   "source": [
    "tic = time.process_time()\n",
    "\n",
    "formulas = []\n",
    "r2 = []\n",
    "r2a = []\n",
    "aic = []\n",
    "bic = []\n",
    "\n",
    "for kk in range(1,len(X.columns)):\n",
    "    fit = SelectKBest(score_func=f_regression, k=kk).fit(X,y) \n",
    "    formula = form(X.columns[fit.get_support()],y)\n",
    "    model = smf.ols(formula,crime).fit()\n",
    "    formulas.append(formula)\n",
    "    r2.append(model.rsquared)\n",
    "    r2a.append(model.rsquared_adj)\n",
    "    aic.append(model.aic)\n",
    "    bic.append(model.bic)\n",
    "kbest_results = pd.DataFrame({'Formula':formulas,'R2':r2,'R2a':r2a,'AIC':aic,'BIC':bic})\n",
    "\n",
    "toc = time.process_time()\n",
    "print(f'This took a decent laptop {toc-tic:.4f} seconds to run.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "2d209aa3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Formula    Crime ~ M + So + Ed + Po1 + Po2 + LF + MF + Po...\n",
       "R2                                                  0.800413\n",
       "R2a                                                 0.713094\n",
       "AIC                                               646.662873\n",
       "BIC                                               674.415087\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_results.iloc[kbest_results['R2a'].argmax()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "3148748b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Formula    Crime ~ M + So + Ed + Po1 + Po2 + LF + MF + Po...\n",
       "R2                                                  0.800413\n",
       "R2a                                                 0.713094\n",
       "AIC                                               646.662873\n",
       "BIC                                               674.415087\n",
       "Name: 13, dtype: object"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_results.iloc[kbest_results['AIC'].argmin()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "102beb5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Formula    Crime ~ Ed + Po1 + Po2 + LF + MF + Pop + Wealt...\n",
       "R2                                                  0.733915\n",
       "R2a                                                 0.669191\n",
       "AIC                                               650.178597\n",
       "BIC                                               668.680074\n",
       "Name: 8, dtype: object"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kbest_results.iloc[kbest_results['BIC'].argmin()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f200938",
   "metadata": {},
   "source": [
    "## Recursive Feature Elimination\n",
    "This is basically Stepwise Regression without relying on p-values, instead using magnitude of parameter estimates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52b14089",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bed63f96",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = LinearRegression(fit_intercept=True)\n",
    "rfe = RFE(model, n_features_to_select=6)\n",
    "fit = rfe.fit(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1bd00abd",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['So', 'Ed', 'Po1', 'Po2', 'LF', 'Prob'], dtype='object')"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.columns[fit.get_support()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f1db2cd4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formula = form(X.columns[fit.get_support()],y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "99e45646",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "        <td>Model:</td>               <td>OLS</td>         <td>Adj. R-squared:</td>     <td>0.567</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Dependent Variable:</td>       <td>Crime</td>             <td>AIC:</td>         <td>660.4977</td>\n",
       "</tr>\n",
       "<tr>\n",
       "         <td>Date:</td>        <td>2023-08-21 17:51</td>        <td>BIC:</td>         <td>673.4487</td>\n",
       "</tr>\n",
       "<tr>\n",
       "   <td>No. Observations:</td>         <td>47</td>          <td>Log-Likelihood:</td>    <td>-323.25</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Df Model:</td>              <td>6</td>           <td>F-statistic:</td>       <td>11.04</td> \n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Df Residuals:</td>           <td>40</td>        <td>Prob (F-statistic):</td> <td>3.12e-07</td>\n",
       "</tr>\n",
       "<tr>\n",
       "      <td>R-squared:</td>            <td>0.623</td>            <td>Scale:</td>         <td>64774.</td> \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "      <td></td>         <th>Coef.</th>   <th>Std.Err.</th>     <th>t</th>     <th>P>|t|</th>   <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th> <td>-1329.6954</td> <td>716.5877</td>  <td>-1.8556</td> <td>0.0709</td> <td>-2777.9731</td> <td>118.5823</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>So</th>         <td>413.9895</td>  <td>122.2126</td>  <td>3.3875</td>  <td>0.0016</td>  <td>166.9886</td>  <td>660.9903</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Ed</th>          <td>67.2912</td>   <td>57.4824</td>  <td>1.1706</td>  <td>0.2487</td>  <td>-48.8850</td>  <td>183.4674</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po1</th>        <td>239.1621</td>  <td>117.3743</td>  <td>2.0376</td>  <td>0.0482</td>   <td>1.9398</td>   <td>476.3845</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Po2</th>        <td>-168.4159</td> <td>127.2207</td>  <td>-1.3238</td> <td>0.1931</td>  <td>-425.5385</td>  <td>88.7066</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>LF</th>         <td>1658.9000</td> <td>1226.2691</td> <td>1.3528</td>  <td>0.1837</td>  <td>-819.4823</td> <td>4137.2824</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob</th>      <td>-4875.0868</td> <td>2094.1173</td> <td>-2.3280</td> <td>0.0251</td> <td>-9107.4556</td> <td>-642.7179</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "     <td>Omnibus:</td>    <td>0.059</td>  <td>Durbin-Watson:</td>   <td>2.190</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <td>Prob(Omnibus):</td> <td>0.971</td> <td>Jarque-Bera (JB):</td> <td>0.101</td>\n",
       "</tr>\n",
       "<tr>\n",
       "       <td>Skew:</td>     <td>0.068</td>     <td>Prob(JB):</td>     <td>0.951</td>\n",
       "</tr>\n",
       "<tr>\n",
       "     <td>Kurtosis:</td>   <td>2.817</td>  <td>Condition No.:</td>    <td>915</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary2.Summary'>\n",
       "\"\"\"\n",
       "                 Results: Ordinary least squares\n",
       "==================================================================\n",
       "Model:               OLS              Adj. R-squared:     0.567   \n",
       "Dependent Variable:  Crime            AIC:                660.4977\n",
       "Date:                2023-08-21 17:51 BIC:                673.4487\n",
       "No. Observations:    47               Log-Likelihood:     -323.25 \n",
       "Df Model:            6                F-statistic:        11.04   \n",
       "Df Residuals:        40               Prob (F-statistic): 3.12e-07\n",
       "R-squared:           0.623            Scale:              64774.  \n",
       "------------------------------------------------------------------\n",
       "            Coef.     Std.Err.    t    P>|t|    [0.025     0.975] \n",
       "------------------------------------------------------------------\n",
       "Intercept -1329.6954  716.5877 -1.8556 0.0709 -2777.9731  118.5823\n",
       "So          413.9895  122.2126  3.3875 0.0016   166.9886  660.9903\n",
       "Ed           67.2912   57.4824  1.1706 0.2487   -48.8850  183.4674\n",
       "Po1         239.1621  117.3743  2.0376 0.0482     1.9398  476.3845\n",
       "Po2        -168.4159  127.2207 -1.3238 0.1931  -425.5385   88.7066\n",
       "LF         1658.9000 1226.2691  1.3528 0.1837  -819.4823 4137.2824\n",
       "Prob      -4875.0868 2094.1173 -2.3280 0.0251 -9107.4556 -642.7179\n",
       "------------------------------------------------------------------\n",
       "Omnibus:               0.059        Durbin-Watson:           2.190\n",
       "Prob(Omnibus):         0.971        Jarque-Bera (JB):        0.101\n",
       "Skew:                  0.068        Prob(JB):                0.951\n",
       "Kurtosis:              2.817        Condition No.:           915  \n",
       "==================================================================\n",
       "\n",
       "\"\"\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smf.ols(formula, crime).fit().summary2()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a4d3f921",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "Xstd = StandardScaler().fit_transform(X)\n",
    "Xstd = pd.DataFrame(data=Xstd, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e9ed1297",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "formula = form(X.columns,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "f719d585",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 Results: Ordinary least squares\n",
      "=================================================================\n",
      "Model:              OLS              Adj. R-squared:     0.708   \n",
      "Dependent Variable: Crime            AIC:                648.0291\n",
      "Date:               2023-08-21 17:53 BIC:                677.6314\n",
      "No. Observations:   47               Log-Likelihood:     -308.01 \n",
      "Df Model:           15               F-statistic:        8.429   \n",
      "Df Residuals:       31               Prob (F-statistic): 3.54e-07\n",
      "R-squared:          0.803            Scale:              43708.  \n",
      "-----------------------------------------------------------------\n",
      "              Coef.   Std.Err.    t    P>|t|    [0.025    0.975] \n",
      "-----------------------------------------------------------------\n",
      "Intercept    905.0851  30.4952 29.6796 0.0000  842.8898  967.2804\n",
      "M            109.2012  51.8638  2.1055 0.0434    3.4243  214.9780\n",
      "So            -1.8023  70.4880 -0.0256 0.9798 -145.5634  141.9589\n",
      "Ed           208.4251  68.7154  3.0332 0.0049   68.2792  348.5710\n",
      "Po1          566.8662 311.9743  1.8170 0.0789  -69.4095 1203.1420\n",
      "Po2         -302.6858 324.9694 -0.9314 0.3588 -965.4652  360.0937\n",
      "LF           -26.5395  58.7592 -0.4517 0.6547 -146.3796   93.3006\n",
      "MF            50.7448  59.3359  0.8552 0.3990  -70.2716  171.7612\n",
      "Pop          -27.6080  48.5698 -0.5684 0.5738 -126.6668   71.4508\n",
      "NW            42.7716  65.9295  0.6487 0.5213  -91.6925  177.2356\n",
      "U1          -103.9319  75.0945 -1.3840 0.1762 -257.0882   49.2244\n",
      "U2           140.1987  68.7927  2.0380 0.0502   -0.1050  280.5023\n",
      "Wealth        91.7993  98.9585  0.9277 0.3608 -110.0279  293.6265\n",
      "Ineq         278.9382  89.6606  3.1110 0.0040   96.0741  461.8023\n",
      "Prob        -109.2133  51.1143 -2.1366 0.0406 -213.4617   -4.9650\n",
      "Time         -24.3917  50.2364 -0.4855 0.6307 -126.8496   78.0662\n",
      "-----------------------------------------------------------------\n",
      "Omnibus:              2.036        Durbin-Watson:           1.723\n",
      "Prob(Omnibus):        0.361        Jarque-Bera (JB):        1.135\n",
      "Skew:                 0.198        Prob(JB):                0.567\n",
      "Kurtosis:             3.651        Condition No.:           36   \n",
      "=================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = smf.ols(formula, Xstd.join(y)).fit()\n",
    "print(model.summary2())\n",
    "# print(model.summary2().tables[1].sort_values('Coef.',ascending=False,key=abs)['Coef.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b032a07f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    905.085106\n",
      "Po1          566.648663\n",
      "Po2         -302.117718\n",
      "Ineq         278.080663\n",
      "Ed           208.320589\n",
      "U2           139.808715\n",
      "Prob        -109.401453\n",
      "M            109.075166\n",
      "U1          -103.203798\n",
      "Wealth        91.215642\n",
      "MF            50.510115\n",
      "NW            42.061587\n",
      "Pop          -27.612448\n",
      "LF           -25.829084\n",
      "Time         -24.222806\n",
      "Name: Coef., dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula = form(X.columns,y)\n",
    "formula += ' - So'\n",
    "model = smf.ols(formula, Xstd.join(y)).fit()\n",
    "print(model.summary2().tables[1].sort_values('Coef.',ascending=False,key=abs)['Coef.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50460a54",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    905.085106\n",
      "Po1          486.720869\n",
      "Ineq         280.631937\n",
      "Po2         -203.387151\n",
      "Ed           198.426855\n",
      "U2           139.412519\n",
      "M            111.029144\n",
      "Prob         -90.425657\n",
      "U1           -89.402928\n",
      "Wealth        85.849659\n",
      "MF            41.856653\n",
      "Pop          -37.087781\n",
      "NW            29.317738\n",
      "Name: Coef., dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula = form(X.columns,y)\n",
    "formula += ' - So - Time - LF'\n",
    "model = smf.ols(formula, Xstd.join(y)).fit()\n",
    "print(model.summary2().tables[1].sort_values('Coef.',ascending=False,key=abs)['Coef.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "541edb61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    905.085106\n",
      "Po1          473.961149\n",
      "Ineq         292.523629\n",
      "Ed           194.586853\n",
      "Po2         -176.785793\n",
      "U2           142.642310\n",
      "M            121.300655\n",
      "U1           -90.914389\n",
      "Prob         -84.205101\n",
      "Wealth        81.092777\n",
      "MF            38.393079\n",
      "Pop          -35.658671\n",
      "Name: Coef., dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula = form(X.columns,y)\n",
    "formula += ' - So - Time - LF - NW'\n",
    "model = smf.ols(formula, Xstd.join(y)).fit()\n",
    "print(model.summary2().tables[1].sort_values('Coef.',ascending=False,key=abs)['Coef.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "6c8c4939",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    905.085106\n",
      "Po1          434.462305\n",
      "Ineq         274.472696\n",
      "Ed           193.350563\n",
      "Po2         -156.843790\n",
      "U2           143.912814\n",
      "M            123.796979\n",
      "U1           -97.418899\n",
      "Prob         -77.897614\n",
      "Wealth        72.554853\n",
      "MF            55.676023\n",
      "Name: Coef., dtype: float64\n"
     ]
    }
   ],
   "source": [
    "formula = form(X.columns,y)\n",
    "formula += ' - So - Time - LF - NW - Pop'\n",
    "model = smf.ols(formula, Xstd.join(y)).fit()\n",
    "print(model.summary2().tables[1].sort_values('Coef.',ascending=False,key=abs)['Coef.'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4cd9e304",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intercept    905.085106\n",
      "Po1          566.913479\n",
      "Ineq         326.865102\n",
      "Po2         -253.725083\n",
      "Wealth       168.065292\n",
      "Ed           163.811991\n",
      "M            112.806354\n",
      "Name: Coef., dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Skipping ahead to the final 6 using the same method repeatedly\n",
    "formula = form(X.columns,y)\n",
    "formula += ' - So - Time - LF - NW - Pop - MF - U1 - U2 - Prob'\n",
    "model = smf.ols(formula, Xstd.join(y)).fit()\n",
    "print(model.summary2().tables[1].sort_values('Coef.',ascending=False,key=abs)['Coef.'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f58259e",
   "metadata": {},
   "source": [
    "## That's all for now!\n",
    "You've now been exposed to three possible methods: brute force, k-best, and RFE. Hopefully you've seen that none of them are particularly well-suited to most problems. If nothing else, the brute force method should make you appreciate the difficulty of finding an algorithm that effectively sorts through all possible models in an efficient manner. \n",
    "\n",
    "Add additional note: in application, brute force will also almost guarantee you overfit the model; the \"optimal\" model in the training set is rarely effective in the validation set. If you select a model off of the validation set, you overuse that set and it is rarely effective in the test set. This is another reason we don't typically use brute force."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0deedeb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
